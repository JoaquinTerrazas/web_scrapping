{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943046b6",
   "metadata": {},
   "source": [
    "# Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609f9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0484b",
   "metadata": {},
   "source": [
    "# Guardar resultados en la carpeta output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0470a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando carpeta existente: ../output\n",
      "=== CONFIGURACIÓN COMPLETADA ===\n",
      "Directorio de trabajo: c:\\Users\\Usuario\\Desktop\\CICLOWAA8\\data science\\web_scrapping\\code\n",
      "Carpeta de salida: ../output\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Carpeta '{output_dir}' creada\")\n",
    "else:\n",
    "    print(f\"Usando carpeta existente: {output_dir}\")\n",
    "\n",
    "print(\"=== CONFIGURACIÓN COMPLETADA ===\")\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")\n",
    "print(f\"Carpeta de salida: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c659c00",
   "metadata": {},
   "source": [
    "# Parte 1: Web Scraping Top Stock Gainers from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a9ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PARTE 1: WEB SCRAPING ===\n",
      "Procesando página 1...\n",
      "1. CYTK - Cytokinetics, Incorporated\n",
      "2. UTHR - United Therapeutics Corporation\n",
      "3. IONS - Ionis Pharmaceuticals, Inc.\n",
      "4. ARWR - Arrowhead Pharmaceuticals, Inc.\n",
      "5. SBSW - Sibanye Stillwater Limited\n",
      "6. HMY - Harmony Gold Mining Company Limited\n",
      "7. JOYY - JOYY Inc.\n",
      "8. IREN - IREN Limited\n",
      "9. MENS - Jyong Biotech Ltd.\n",
      "10. AL - Air Lease Corporation\n",
      "11. ULTA - Ulta Beauty, Inc.\n",
      "12. ONC - BeOne Medicines AG\n",
      "13. INSM - Insmed Incorporated\n",
      "14. DOOO - BRP Inc.\n",
      "15. QXO - QXO, Inc.\n",
      "16. RARE - Ultragenyx Pharmaceutical Inc.\n",
      "17. EQX - Equinox Gold Corp.\n",
      "18. PTCT - PTC Therapeutics, Inc.\n",
      "19. BEKE - KE Holdings Inc.\n",
      "20. CRNX - Crinetics Pharmaceuticals, Inc.\n",
      "21. CROX - Crocs, Inc.\n",
      "22. AGI - Alamos Gold Inc.\n",
      "23. CIFR - Cipher Mining Inc.\n",
      "24. LI - Li Auto Inc.\n",
      "25. BHC - Bausch Health Companies Inc.\n",
      "Procesando página 2...\n",
      "26. BIIB - Biogen Inc.\n",
      "27. ASND - Ascendis Pharma A/S\n",
      "28. MUR - Murphy Oil Corporation\n",
      "29. AU - AngloGold Ashanti plc\n",
      "30. GMAB - Genmab A/S\n",
      "31. RL - Ralph Lauren Corporation\n",
      "32. W - Wayfair Inc.\n",
      "33. PFGC - Performance Food Group Company\n",
      "34. HL - Hecla Mining Company\n",
      "35. ETOR - eToro Group Ltd.\n",
      "36. APGE - Apogee Therapeutics, Inc.\n",
      "37. AG - First Majestic Silver Corp.\n",
      "38. GFI - Gold Fields Limited\n",
      "39. AEO - American Eagle Outfitters, Inc.\n",
      "40. LQDA - Liquidia Corporation\n",
      "41. ARX - Accelerant Holdings\n",
      "\n",
      "Total acciones obtenidas: 41\n",
      "✅ PARTE 1 COMPLETADA - Archivos guardados en 'output/':\n",
      "  - top_50_gainers_20250902_114338.csv\n",
      "  - latest_gainers.csv\n"
     ]
    }
   ],
   "source": [
    "def scrape_yahoo_gainers():\n",
    "    \"\"\"Función optimizada para scrapear los top 50 gainers de Yahoo Finance\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    symbols, names = [], []\n",
    "    \n",
    "    try:\n",
    "        driver.get(\"https://finance.yahoo.com/markets/stocks/gainers\")\n",
    "        driver.maximize_window()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table\")))\n",
    "        time.sleep(5)\n",
    "        \n",
    "        page = 1\n",
    "        while len(symbols) < 50:\n",
    "            print(f\"Procesando página {page}...\")\n",
    "            rows = driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "            \n",
    "            for row in rows:\n",
    "                if len(symbols) >= 50:\n",
    "                    break\n",
    "                try:\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    if len(cells) >= 2:\n",
    "                        # Obtener symbol y name\n",
    "                        symbol_cell = cells[0]\n",
    "                        symbol = symbol_cell.find_element(By.TAG_NAME, \"a\").text.strip() if symbol_cell.find_elements(By.TAG_NAME, \"a\") else symbol_cell.text.strip()\n",
    "                        name = cells[1].text.strip()\n",
    "                        \n",
    "                        # Validar y agregar\n",
    "                        symbol = symbol.replace('$', '').replace(',', '').strip()\n",
    "                        if symbol and name and symbol not in symbols and len(symbol) <= 6:\n",
    "                            symbols.append(symbol)\n",
    "                            names.append(name)\n",
    "                            print(f\"{len(symbols)}. {symbol} - {name}\")\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Buscar siguiente página si es necesario\n",
    "            if len(symbols) < 50:\n",
    "                next_found = False\n",
    "                for selector in [\"button[aria-label*='next']\", \"a[aria-label*='next']\"]:\n",
    "                    try:\n",
    "                        next_button = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                        if next_button.is_enabled():\n",
    "                            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                            next_found = True\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if not next_found:\n",
    "                    break\n",
    "                page += 1\n",
    "                time.sleep(4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el scraping: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return symbols[:50], names[:50]\n",
    "\n",
    "# EJECUCIÓN PARTE 1\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== PARTE 1: WEB SCRAPING ===\")\n",
    "    symbols_list, names_list = scrape_yahoo_gainers()\n",
    "    \n",
    "    # Crear DataFrame con los resultados\n",
    "    gainers_df = pd.DataFrame({'Symbol': symbols_list, 'Name': names_list})\n",
    "    print(f\"\\nTotal acciones obtenidas: {len(gainers_df)}\")\n",
    "    \n",
    "    # Guardar resultados con timestamp único en carpeta output\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    gainers_df.to_csv(os.path.join(output_dir, f'top_50_gainers_{timestamp}.csv'), index=False)\n",
    "    gainers_df.to_csv(os.path.join(output_dir, 'latest_gainers.csv'), index=False)\n",
    "    \n",
    "    print(\"✅ PARTE 1 COMPLETADA - Archivos guardados en 'output/':\")\n",
    "    print(f\"  - top_50_gainers_{timestamp}.csv\")\n",
    "    print(\"  - latest_gainers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56b0c7",
   "metadata": {},
   "source": [
    "# Parte 2: Historical Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5db2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PARTE 2: DATOS HISTÓRICOS ===\n",
      "Símbolos cargados desde 'output/': 41\n",
      "Descargando datos históricos para 41 símbolos...\n",
      "[1/41] CYTK ✅\n",
      "[2/41] UTHR ✅\n",
      "[3/41] IONS ✅\n",
      "[4/41] ARWR ✅\n",
      "[5/41] SBSW ✅\n",
      "[6/41] HMY ✅\n",
      "[7/41] JOYY ✅\n",
      "[8/41] IREN ✅\n",
      "[9/41] MENS ✅\n",
      "[10/41] AL ✅\n",
      "[11/41] ULTA ✅\n",
      "[12/41] ONC ✅\n",
      "[13/41] INSM ✅\n",
      "[14/41] DOOO ✅\n",
      "[15/41] QXO ✅\n",
      "[16/41] RARE ✅\n",
      "[17/41] EQX ✅\n",
      "[18/41] PTCT ✅\n",
      "[19/41] BEKE ✅\n",
      "[20/41] CRNX ✅\n",
      "[21/41] CROX ✅\n",
      "[22/41] AGI ✅\n",
      "[23/41] CIFR ✅\n",
      "[24/41] LI ✅\n",
      "[25/41] BHC ✅\n",
      "[26/41] BIIB ✅\n",
      "[27/41] ASND ✅\n",
      "[28/41] MUR ✅\n",
      "[29/41] AU ✅\n",
      "[30/41] GMAB ✅\n",
      "[31/41] RL ✅\n",
      "[32/41] W ✅\n",
      "[33/41] PFGC ✅\n",
      "[34/41] HL ✅\n",
      "[35/41] ETOR ✅\n",
      "[36/41] APGE ✅\n",
      "[37/41] AG ✅\n",
      "[38/41] GFI ✅\n",
      "[39/41] AEO ✅\n",
      "[40/41] LQDA ✅\n",
      "[41/41] ARX ✅\n",
      "\n",
      "DataFrame final: 12 fechas x 41 símbolos\n",
      "Símbolos exitosos: 41/41\n",
      "✅ Datos guardados: 12 fechas x 41 símbolos\n",
      "✅ PARTE 2 COMPLETADA - Archivos guardados en 'output/':\n",
      "  - monthly_historical_data_20250902_114405.csv\n",
      "  - monthly_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "def retrieve_historical_data(symbols_list, period=\"1y\", interval=\"1mo\"):\n",
    "    \"\"\"Función optimizada para obtener datos históricos\"\"\"\n",
    "    print(f\"Descargando datos históricos para {len(symbols_list)} símbolos...\")\n",
    "    \n",
    "    historical_data = {}\n",
    "    successful_count = 0\n",
    "    \n",
    "    for i, symbol in enumerate(symbols_list, 1):\n",
    "        try:\n",
    "            hist_data = yf.Ticker(symbol).history(period=period, interval=interval)\n",
    "            if not hist_data.empty and len(hist_data['Close']) > 0:\n",
    "                historical_data[symbol] = hist_data['Close']\n",
    "                successful_count += 1\n",
    "                print(f\"[{i}/{len(symbols_list)}] {symbol} ✅\")\n",
    "            else:\n",
    "                print(f\"[{i}/{len(symbols_list)}] {symbol} ❌ Sin datos\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}/{len(symbols_list)}] {symbol} ❌ Error: {str(e)[:30]}...\")\n",
    "        time.sleep(0.1)  # Evitar sobrecarga de la API\n",
    "    \n",
    "    if historical_data:\n",
    "        # Crear DataFrame combinado\n",
    "        combined_df = pd.DataFrame(historical_data)\n",
    "        combined_df = combined_df.dropna(how='all')\n",
    "        \n",
    "        # Limpiar fechas futuras y normalizar\n",
    "        today = pd.Timestamp.now().tz_localize(None)\n",
    "        combined_df.index = pd.to_datetime(combined_df.index).tz_localize(None)\n",
    "        combined_df = combined_df.loc[combined_df.index <= today].sort_index(ascending=False)\n",
    "        \n",
    "        print(f\"\\nDataFrame final: {combined_df.shape[0]} fechas x {combined_df.shape[1]} símbolos\")\n",
    "        print(f\"Símbolos exitosos: {successful_count}/{len(symbols_list)}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"❌ No se obtuvieron datos para ningún símbolo\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# EJECUCIÓN PARTE 2\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== PARTE 2: DATOS HISTÓRICOS ===\")\n",
    "    \n",
    "    # Cargar símbolos de la Parte 1 desde carpeta output\n",
    "    try:\n",
    "        gainers_df = pd.read_csv(os.path.join(output_dir, 'latest_gainers.csv'))\n",
    "        symbols_list = gainers_df['Symbol'].tolist()\n",
    "        print(f\"Símbolos cargados desde 'output/': {len(symbols_list)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Ejecuta primero la Parte 1\")\n",
    "        symbols_list = []\n",
    "    \n",
    "    if symbols_list:\n",
    "        # Descargar datos históricos\n",
    "        historical_df = retrieve_historical_data(symbols_list)\n",
    "        \n",
    "        if not historical_df.empty:\n",
    "            # Guardar datos históricos en carpeta output\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            historical_df.to_csv(os.path.join(output_dir, f'monthly_historical_data_{timestamp}.csv'))\n",
    "            historical_df.to_csv(os.path.join(output_dir, 'monthly_historical_data.csv'))\n",
    "            print(f\"✅ Datos guardados: {historical_df.shape[0]} fechas x {historical_df.shape[1]} símbolos\")\n",
    "            \n",
    "            print(\"✅ PARTE 2 COMPLETADA - Archivos guardados en 'output/':\")\n",
    "            print(f\"  - monthly_historical_data_{timestamp}.csv\")\n",
    "            print(\"  - monthly_historical_data.csv\")\n",
    "        else:\n",
    "            print(\"❌ PARTE 2 FALLÓ - No se obtuvieron datos históricos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841836c",
   "metadata": {},
   "source": [
    "# Parte 3: Portfolio Construction & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7d95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PARTE 3: ANÁLISIS DE PORTAFOLIO ===\n",
      "=== ANÁLISIS DE PORTAFOLIO DE MOMENTUM ===\n",
      "Datos cargados desde 'output/': 12 fechas x 41 símbolos\n",
      "Período selección: 2024-10-01 a 2025-03-01\n",
      "Período análisis: 2025-04-01 a 2025-09-01\n",
      "\n",
      "✅ Portafolio seleccionado (Top 10):\n",
      "   1. HMY    -  +36.97%\n",
      "   2. LQDA   -  +35.94%\n",
      "   3. ONC    -  +34.31%\n",
      "   4. GFI    -  +34.04%\n",
      "   5. AU     -  +33.53%\n",
      "   6. AGI    -  +32.68%\n",
      "   7. PTCT   -  +27.66%\n",
      "   8. ASND   -  +26.90%\n",
      "   9. EQX    -  +24.19%\n",
      "  10. JOYY   -  +23.29%\n",
      "\n",
      "📊 ESTADÍSTICAS DEL PORTAFOLIO:\n",
      "  • Rendimiento total:        +33.69%\n",
      "  • Rendimiento mensual:       +5.18%\n",
      "  • Volatilidad anualizada:    26.72%\n",
      "\n",
      "📈 RENDIMIENTOS INDIVIDUALES (Período análisis):\n",
      "  LQDA  : +104.15%\n",
      "  GFI   :  +53.13%\n",
      "  JOYY  :  +47.73%\n",
      "  AU    :  +41.43%\n",
      "  EQX   :  +37.01%\n",
      "  ONC   :  +25.60%\n",
      "  ASND  :  +18.33%\n",
      "  AGI   :  +11.26%\n",
      "  PTCT  :   +3.73%\n",
      "  HMY   :   -9.89%\n",
      "\n",
      "✅ PARTE 3 COMPLETADA\n",
      "\n",
      "🎯 ESTRATEGIA IMPLEMENTADA:\n",
      "  - Selección: Top 10 con mayor momentum (primeros 6 meses)\n",
      "  - Portafolio: Equal-weighted (10% por acción)\n",
      "  - Análisis: Performance últimos 6 meses\n"
     ]
    }
   ],
   "source": [
    "def analyze_momentum_portfolio():\n",
    "    \"\"\"Función optimizada para construir y analizar portafolio de momentum\"\"\"\n",
    "    print(\"=== ANÁLISIS DE PORTAFOLIO DE MOMENTUM ===\")\n",
    "    \n",
    "    # Cargar datos históricos desde carpeta output\n",
    "    try:\n",
    "        historical_df = pd.read_csv(os.path.join(output_dir, 'monthly_historical_data.csv'), index_col=0, parse_dates=True)\n",
    "        historical_df = historical_df.sort_index(ascending=True)\n",
    "        print(f\"Datos cargados desde 'output/': {historical_df.shape[0]} fechas x {historical_df.shape[1]} símbolos\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ No se encontró 'output/monthly_historical_data.csv'\")\n",
    "        print(\"Ejecuta primero las Partes 1 y 2\")\n",
    "        return None\n",
    "    \n",
    "    # Validar que tenemos suficientes datos\n",
    "    if len(historical_df) < 6:\n",
    "        print(f\"❌ Datos insuficientes: solo {len(historical_df)} meses disponibles\")\n",
    "        return None\n",
    "    \n",
    "    # PASO 1: Dividir datos en períodos de 6 meses\n",
    "    first_6_months = historical_df.iloc[:6]\n",
    "    last_6_months = historical_df.iloc[6:12] if len(historical_df) >= 12 else historical_df.iloc[6:]\n",
    "    \n",
    "    print(f\"Período selección: {first_6_months.index[0].strftime('%Y-%m-%d')} a {first_6_months.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Período análisis: {last_6_months.index[0].strftime('%Y-%m-%d')} a {last_6_months.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # PASO 2: Calcular rendimientos acumulados primeros 6 meses\n",
    "    complete_stocks_first = first_6_months.dropna(axis=1)\n",
    "    if len(complete_stocks_first.columns) < 10:\n",
    "        print(f\"⚠️ Solo {len(complete_stocks_first.columns)} acciones con datos completos\")\n",
    "    \n",
    "    cumulative_returns = ((complete_stocks_first.iloc[-1] / complete_stocks_first.iloc[0]) - 1) * 100\n",
    "    cumulative_returns = cumulative_returns.sort_values(ascending=False)\n",
    "    \n",
    "    # PASO 3: Seleccionar top 10 para el portafolio\n",
    "    num_stocks = min(10, len(cumulative_returns))\n",
    "    portfolio_symbols = cumulative_returns.head(num_stocks).index.tolist()\n",
    "    \n",
    "    print(f\"\\n✅ Portafolio seleccionado (Top {num_stocks}):\")\n",
    "    for i, symbol in enumerate(portfolio_symbols, 1):\n",
    "        print(f\"  {i:2d}. {symbol:6s} - {cumulative_returns[symbol]:+7.2f}%\")\n",
    "    \n",
    "    # PASO 4: Analizar performance en período de análisis\n",
    "    portfolio_data = last_6_months[portfolio_symbols].dropna(axis=1)\n",
    "    if portfolio_data.empty:\n",
    "        print(\"❌ No hay datos suficientes para análisis de performance\")\n",
    "        return None\n",
    "    \n",
    "    # Calcular rendimientos mensuales individuales y del portafolio\n",
    "    individual_monthly_returns = portfolio_data.pct_change().fillna(0) * 100\n",
    "    portfolio_monthly_returns = individual_monthly_returns.mean(axis=1)  # Equal-weighted\n",
    "    \n",
    "    # PASO 5: Calcular estadísticas del portafolio\n",
    "    total_return = ((1 + portfolio_monthly_returns/100).cumprod().iloc[-1] - 1) * 100\n",
    "    volatility = portfolio_monthly_returns.std() * np.sqrt(12)  # Anualizada\n",
    "    avg_monthly_return = portfolio_monthly_returns.mean()\n",
    "    \n",
    "    print(f\"\\n📊 ESTADÍSTICAS DEL PORTAFOLIO:\")\n",
    "    print(f\"  • Rendimiento total:       {total_return:+7.2f}%\")\n",
    "    print(f\"  • Rendimiento mensual:     {avg_monthly_return:+7.2f}%\")\n",
    "    print(f\"  • Volatilidad anualizada:  {volatility:7.2f}%\")\n",
    "    \n",
    "    # PASO 6: Mostrar rendimientos individuales período análisis\n",
    "    individual_cumulative = ((portfolio_data.iloc[-1] / portfolio_data.iloc[0]) - 1) * 100\n",
    "    print(f\"\\n📈 RENDIMIENTOS INDIVIDUALES (Período análisis):\")\n",
    "    for symbol in individual_cumulative.sort_values(ascending=False).index:\n",
    "        print(f\"  {symbol:6s}: {individual_cumulative[symbol]:+7.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'portfolio_symbols': portfolio_data.columns.tolist(),\n",
    "        'individual_monthly_returns': individual_monthly_returns,\n",
    "        'portfolio_monthly_returns': portfolio_monthly_returns,\n",
    "        'portfolio_cumulative_return': total_return,\n",
    "        'portfolio_volatility': volatility\n",
    "    }\n",
    "\n",
    "# EJECUCIÓN PARTE 3\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== PARTE 3: ANÁLISIS DE PORTAFOLIO ===\")\n",
    "    \n",
    "    # Analizar portafolio de momentum\n",
    "    results = analyze_momentum_portfolio()\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n✅ PARTE 3 COMPLETADA\")\n",
    "        print(\"\\n🎯 ESTRATEGIA IMPLEMENTADA:\")\n",
    "        print(\"  - Selección: Top 10 con mayor momentum (primeros 6 meses)\")\n",
    "        print(\"  - Portafolio: Equal-weighted (10% por acción)\")\n",
    "        print(\"  - Análisis: Performance últimos 6 meses\")\n",
    "    else:\n",
    "        print(\"\\n❌ PARTE 3 FALLÓ - Revisa los datos de entrada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
