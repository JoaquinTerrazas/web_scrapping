{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943046b6",
   "metadata": {},
   "source": [
    "# Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609f9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0484b",
   "metadata": {},
   "source": [
    "# Guardar resultados en la carpeta output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0470a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando carpeta existente: ../output\n",
      "=== CONFIGURACI√ìN COMPLETADA ===\n",
      "Directorio de trabajo: c:\\Users\\Usuario\\Desktop\\CICLOWAA8\\data science\\web_scrapping\\code\n",
      "Carpeta de salida: ../output\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Carpeta '{output_dir}' creada\")\n",
    "else:\n",
    "    print(f\"Usando carpeta existente: {output_dir}\")\n",
    "\n",
    "print(\"=== CONFIGURACI√ìN COMPLETADA ===\")\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")\n",
    "print(f\"Carpeta de salida: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c659c00",
   "metadata": {},
   "source": [
    "# Parte 1: Web Scraping Top Stock Gainers from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a9ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PARTE 1: WEB SCRAPING ===\n",
      "Procesando p√°gina 1...\n",
      "1. CYTK - Cytokinetics, Incorporated\n",
      "2. UTHR - United Therapeutics Corporation\n",
      "3. IONS - Ionis Pharmaceuticals, Inc.\n",
      "4. ARWR - Arrowhead Pharmaceuticals, Inc.\n",
      "5. SBSW - Sibanye Stillwater Limited\n",
      "6. HMY - Harmony Gold Mining Company Limited\n",
      "7. JOYY - JOYY Inc.\n",
      "8. IREN - IREN Limited\n",
      "9. MENS - Jyong Biotech Ltd.\n",
      "10. AL - Air Lease Corporation\n",
      "11. ULTA - Ulta Beauty, Inc.\n",
      "12. ONC - BeOne Medicines AG\n",
      "13. INSM - Insmed Incorporated\n",
      "14. DOOO - BRP Inc.\n",
      "15. QXO - QXO, Inc.\n",
      "16. RARE - Ultragenyx Pharmaceutical Inc.\n",
      "17. EQX - Equinox Gold Corp.\n",
      "18. PTCT - PTC Therapeutics, Inc.\n",
      "19. BEKE - KE Holdings Inc.\n",
      "20. CRNX - Crinetics Pharmaceuticals, Inc.\n",
      "21. CROX - Crocs, Inc.\n",
      "22. AGI - Alamos Gold Inc.\n",
      "23. CIFR - Cipher Mining Inc.\n",
      "24. LI - Li Auto Inc.\n",
      "25. BHC - Bausch Health Companies Inc.\n",
      "Procesando p√°gina 2...\n",
      "26. BIIB - Biogen Inc.\n",
      "27. ASND - Ascendis Pharma A/S\n",
      "28. MUR - Murphy Oil Corporation\n",
      "29. AU - AngloGold Ashanti plc\n",
      "30. GMAB - Genmab A/S\n",
      "31. RL - Ralph Lauren Corporation\n",
      "32. W - Wayfair Inc.\n",
      "33. PFGC - Performance Food Group Company\n",
      "34. HL - Hecla Mining Company\n",
      "35. ETOR - eToro Group Ltd.\n",
      "36. APGE - Apogee Therapeutics, Inc.\n",
      "37. AG - First Majestic Silver Corp.\n",
      "38. GFI - Gold Fields Limited\n",
      "39. AEO - American Eagle Outfitters, Inc.\n",
      "40. LQDA - Liquidia Corporation\n",
      "41. ARX - Accelerant Holdings\n",
      "\n",
      "Total acciones obtenidas: 41\n",
      "‚úÖ PARTE 1 COMPLETADA - Archivos guardados en 'output/':\n",
      "  - top_50_gainers_20250902_114338.csv\n",
      "  - latest_gainers.csv\n"
     ]
    }
   ],
   "source": [
    "def scrape_yahoo_gainers():\n",
    "    \"\"\"Funci√≥n optimizada para scrapear los top 50 gainers de Yahoo Finance\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    symbols, names = [], []\n",
    "    \n",
    "    try:\n",
    "        driver.get(\"https://finance.yahoo.com/markets/stocks/gainers\")\n",
    "        driver.maximize_window()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table\")))\n",
    "        time.sleep(5)\n",
    "        \n",
    "        page = 1\n",
    "        while len(symbols) < 50:\n",
    "            print(f\"Procesando p√°gina {page}...\")\n",
    "            rows = driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "            \n",
    "            for row in rows:\n",
    "                if len(symbols) >= 50:\n",
    "                    break\n",
    "                try:\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    if len(cells) >= 2:\n",
    "                        # Obtener symbol y name\n",
    "                        symbol_cell = cells[0]\n",
    "                        symbol = symbol_cell.find_element(By.TAG_NAME, \"a\").text.strip() if symbol_cell.find_elements(By.TAG_NAME, \"a\") else symbol_cell.text.strip()\n",
    "                        name = cells[1].text.strip()\n",
    "                        \n",
    "                        # Validar y agregar\n",
    "                        symbol = symbol.replace('$', '').replace(',', '').strip()\n",
    "                        if symbol and name and symbol not in symbols and len(symbol) <= 6:\n",
    "                            symbols.append(symbol)\n",
    "                            names.append(name)\n",
    "                            print(f\"{len(symbols)}. {symbol} - {name}\")\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Buscar siguiente p√°gina si es necesario\n",
    "            if len(symbols) < 50:\n",
    "                next_found = False\n",
    "                for selector in [\"button[aria-label*='next']\", \"a[aria-label*='next']\"]:\n",
    "                    try:\n",
    "                        next_button = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                        if next_button.is_enabled():\n",
    "                            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                            next_found = True\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if not next_found:\n",
    "                    break\n",
    "                page += 1\n",
    "                time.sleep(4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el scraping: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return symbols[:50], names[:50]\n",
    "\n",
    "# EJECUCI√ìN PARTE 1\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== PARTE 1: WEB SCRAPING ===\")\n",
    "    symbols_list, names_list = scrape_yahoo_gainers()\n",
    "    \n",
    "    # Crear DataFrame con los resultados\n",
    "    gainers_df = pd.DataFrame({'Symbol': symbols_list, 'Name': names_list})\n",
    "    print(f\"\\nTotal acciones obtenidas: {len(gainers_df)}\")\n",
    "    \n",
    "    # Guardar resultados con timestamp √∫nico en carpeta output\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    gainers_df.to_csv(os.path.join(output_dir, f'top_50_gainers_{timestamp}.csv'), index=False)\n",
    "    gainers_df.to_csv(os.path.join(output_dir, 'latest_gainers.csv'), index=False)\n",
    "    \n",
    "    print(\"‚úÖ PARTE 1 COMPLETADA - Archivos guardados en 'output/':\")\n",
    "    print(f\"  - top_50_gainers_{timestamp}.csv\")\n",
    "    print(\"  - latest_gainers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56b0c7",
   "metadata": {},
   "source": [
    "# Parte 2: Historical Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5db2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PARTE 2: DATOS HIST√ìRICOS ===\n",
      "S√≠mbolos cargados desde 'output/': 41\n",
      "Descargando datos hist√≥ricos para 41 s√≠mbolos...\n",
      "[1/41] CYTK ‚úÖ\n",
      "[2/41] UTHR ‚úÖ\n",
      "[3/41] IONS ‚úÖ\n",
      "[4/41] ARWR ‚úÖ\n",
      "[5/41] SBSW ‚úÖ\n",
      "[6/41] HMY ‚úÖ\n",
      "[7/41] JOYY ‚úÖ\n",
      "[8/41] IREN ‚úÖ\n",
      "[9/41] MENS ‚úÖ\n",
      "[10/41] AL ‚úÖ\n",
      "[11/41] ULTA ‚úÖ\n",
      "[12/41] ONC ‚úÖ\n",
      "[13/41] INSM ‚úÖ\n",
      "[14/41] DOOO ‚úÖ\n",
      "[15/41] QXO ‚úÖ\n",
      "[16/41] RARE ‚úÖ\n",
      "[17/41] EQX ‚úÖ\n",
      "[18/41] PTCT ‚úÖ\n",
      "[19/41] BEKE ‚úÖ\n",
      "[20/41] CRNX ‚úÖ\n",
      "[21/41] CROX ‚úÖ\n",
      "[22/41] AGI ‚úÖ\n",
      "[23/41] CIFR ‚úÖ\n",
      "[24/41] LI ‚úÖ\n",
      "[25/41] BHC ‚úÖ\n",
      "[26/41] BIIB ‚úÖ\n",
      "[27/41] ASND ‚úÖ\n",
      "[28/41] MUR ‚úÖ\n",
      "[29/41] AU ‚úÖ\n",
      "[30/41] GMAB ‚úÖ\n",
      "[31/41] RL ‚úÖ\n",
      "[32/41] W ‚úÖ\n",
      "[33/41] PFGC ‚úÖ\n",
      "[34/41] HL ‚úÖ\n",
      "[35/41] ETOR ‚úÖ\n",
      "[36/41] APGE ‚úÖ\n",
      "[37/41] AG ‚úÖ\n",
      "[38/41] GFI ‚úÖ\n",
      "[39/41] AEO ‚úÖ\n",
      "[40/41] LQDA ‚úÖ\n",
      "[41/41] ARX ‚úÖ\n",
      "\n",
      "DataFrame final: 12 fechas x 41 s√≠mbolos\n",
      "S√≠mbolos exitosos: 41/41\n",
      "‚úÖ Datos guardados: 12 fechas x 41 s√≠mbolos\n",
      "‚úÖ PARTE 2 COMPLETADA - Archivos guardados en 'output/':\n",
      "  - monthly_historical_data_20250902_114405.csv\n",
      "  - monthly_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "def retrieve_historical_data(symbols_list, period=\"1y\", interval=\"1mo\"):\n",
    "    \"\"\"Funci√≥n optimizada para obtener datos hist√≥ricos\"\"\"\n",
    "    print(f\"Descargando datos hist√≥ricos para {len(symbols_list)} s√≠mbolos...\")\n",
    "    \n",
    "    historical_data = {}\n",
    "    successful_count = 0\n",
    "    \n",
    "    for i, symbol in enumerate(symbols_list, 1):\n",
    "        try:\n",
    "            hist_data = yf.Ticker(symbol).history(period=period, interval=interval)\n",
    "            if not hist_data.empty and len(hist_data['Close']) > 0:\n",
    "                historical_data[symbol] = hist_data['Close']\n",
    "                successful_count += 1\n",
    "                print(f\"[{i}/{len(symbols_list)}] {symbol} ‚úÖ\")\n",
    "            else:\n",
    "                print(f\"[{i}/{len(symbols_list)}] {symbol} ‚ùå Sin datos\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}/{len(symbols_list)}] {symbol} ‚ùå Error: {str(e)[:30]}...\")\n",
    "        time.sleep(0.1)  # Evitar sobrecarga de la API\n",
    "    \n",
    "    if historical_data:\n",
    "        # Crear DataFrame combinado\n",
    "        combined_df = pd.DataFrame(historical_data)\n",
    "        combined_df = combined_df.dropna(how='all')\n",
    "        \n",
    "        # Limpiar fechas futuras y normalizar\n",
    "        today = pd.Timestamp.now().tz_localize(None)\n",
    "        combined_df.index = pd.to_datetime(combined_df.index).tz_localize(None)\n",
    "        combined_df = combined_df.loc[combined_df.index <= today].sort_index(ascending=False)\n",
    "        \n",
    "        print(f\"\\nDataFrame final: {combined_df.shape[0]} fechas x {combined_df.shape[1]} s√≠mbolos\")\n",
    "        print(f\"S√≠mbolos exitosos: {successful_count}/{len(symbols_list)}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"‚ùå No se obtuvieron datos para ning√∫n s√≠mbolo\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# EJECUCI√ìN PARTE 2\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== PARTE 2: DATOS HIST√ìRICOS ===\")\n",
    "    \n",
    "    # Cargar s√≠mbolos de la Parte 1 desde carpeta output\n",
    "    try:\n",
    "        gainers_df = pd.read_csv(os.path.join(output_dir, 'latest_gainers.csv'))\n",
    "        symbols_list = gainers_df['Symbol'].tolist()\n",
    "        print(f\"S√≠mbolos cargados desde 'output/': {len(symbols_list)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Ejecuta primero la Parte 1\")\n",
    "        symbols_list = []\n",
    "    \n",
    "    if symbols_list:\n",
    "        # Descargar datos hist√≥ricos\n",
    "        historical_df = retrieve_historical_data(symbols_list)\n",
    "        \n",
    "        if not historical_df.empty:\n",
    "            # Guardar datos hist√≥ricos en carpeta output\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            historical_df.to_csv(os.path.join(output_dir, f'monthly_historical_data_{timestamp}.csv'))\n",
    "            historical_df.to_csv(os.path.join(output_dir, 'monthly_historical_data.csv'))\n",
    "            print(f\"‚úÖ Datos guardados: {historical_df.shape[0]} fechas x {historical_df.shape[1]} s√≠mbolos\")\n",
    "            \n",
    "            print(\"‚úÖ PARTE 2 COMPLETADA - Archivos guardados en 'output/':\")\n",
    "            print(f\"  - monthly_historical_data_{timestamp}.csv\")\n",
    "            print(\"  - monthly_historical_data.csv\")\n",
    "        else:\n",
    "            print(\"‚ùå PARTE 2 FALL√ì - No se obtuvieron datos hist√≥ricos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841836c",
   "metadata": {},
   "source": [
    "# Parte 3: Portfolio Construction & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7d95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PARTE 3: AN√ÅLISIS DE PORTAFOLIO ===\n",
      "=== AN√ÅLISIS DE PORTAFOLIO DE MOMENTUM ===\n",
      "Datos cargados desde 'output/': 12 fechas x 41 s√≠mbolos\n",
      "Per√≠odo selecci√≥n: 2024-10-01 a 2025-03-01\n",
      "Per√≠odo an√°lisis: 2025-04-01 a 2025-09-01\n",
      "\n",
      "‚úÖ Portafolio seleccionado (Top 10):\n",
      "   1. HMY    -  +36.97%\n",
      "   2. LQDA   -  +35.94%\n",
      "   3. ONC    -  +34.31%\n",
      "   4. GFI    -  +34.04%\n",
      "   5. AU     -  +33.53%\n",
      "   6. AGI    -  +32.68%\n",
      "   7. PTCT   -  +27.66%\n",
      "   8. ASND   -  +26.90%\n",
      "   9. EQX    -  +24.19%\n",
      "  10. JOYY   -  +23.29%\n",
      "\n",
      "üìä ESTAD√çSTICAS DEL PORTAFOLIO:\n",
      "  ‚Ä¢ Rendimiento total:        +33.69%\n",
      "  ‚Ä¢ Rendimiento mensual:       +5.18%\n",
      "  ‚Ä¢ Volatilidad anualizada:    26.72%\n",
      "\n",
      "üìà RENDIMIENTOS INDIVIDUALES (Per√≠odo an√°lisis):\n",
      "  LQDA  : +104.15%\n",
      "  GFI   :  +53.13%\n",
      "  JOYY  :  +47.73%\n",
      "  AU    :  +41.43%\n",
      "  EQX   :  +37.01%\n",
      "  ONC   :  +25.60%\n",
      "  ASND  :  +18.33%\n",
      "  AGI   :  +11.26%\n",
      "  PTCT  :   +3.73%\n",
      "  HMY   :   -9.89%\n",
      "\n",
      "‚úÖ PARTE 3 COMPLETADA\n",
      "\n",
      "üéØ ESTRATEGIA IMPLEMENTADA:\n",
      "  - Selecci√≥n: Top 10 con mayor momentum (primeros 6 meses)\n",
      "  - Portafolio: Equal-weighted (10% por acci√≥n)\n",
      "  - An√°lisis: Performance √∫ltimos 6 meses\n"
     ]
    }
   ],
   "source": [
    "def analyze_momentum_portfolio():\n",
    "    \"\"\"Funci√≥n optimizada para construir y analizar portafolio de momentum\"\"\"\n",
    "    print(\"=== AN√ÅLISIS DE PORTAFOLIO DE MOMENTUM ===\")\n",
    "    \n",
    "    # Cargar datos hist√≥ricos desde carpeta output\n",
    "    try:\n",
    "        historical_df = pd.read_csv(os.path.join(output_dir, 'monthly_historical_data.csv'), index_col=0, parse_dates=True)\n",
    "        historical_df = historical_df.sort_index(ascending=True)\n",
    "        print(f\"Datos cargados desde 'output/': {historical_df.shape[0]} fechas x {historical_df.shape[1]} s√≠mbolos\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå No se encontr√≥ 'output/monthly_historical_data.csv'\")\n",
    "        print(\"Ejecuta primero las Partes 1 y 2\")\n",
    "        return None\n",
    "    \n",
    "    # Validar que tenemos suficientes datos\n",
    "    if len(historical_df) < 6:\n",
    "        print(f\"‚ùå Datos insuficientes: solo {len(historical_df)} meses disponibles\")\n",
    "        return None\n",
    "    \n",
    "    # PASO 1: Dividir datos en per√≠odos de 6 meses\n",
    "    first_6_months = historical_df.iloc[:6]\n",
    "    last_6_months = historical_df.iloc[6:12] if len(historical_df) >= 12 else historical_df.iloc[6:]\n",
    "    \n",
    "    print(f\"Per√≠odo selecci√≥n: {first_6_months.index[0].strftime('%Y-%m-%d')} a {first_6_months.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Per√≠odo an√°lisis: {last_6_months.index[0].strftime('%Y-%m-%d')} a {last_6_months.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # PASO 2: Calcular rendimientos acumulados primeros 6 meses\n",
    "    complete_stocks_first = first_6_months.dropna(axis=1)\n",
    "    if len(complete_stocks_first.columns) < 10:\n",
    "        print(f\"‚ö†Ô∏è Solo {len(complete_stocks_first.columns)} acciones con datos completos\")\n",
    "    \n",
    "    cumulative_returns = ((complete_stocks_first.iloc[-1] / complete_stocks_first.iloc[0]) - 1) * 100\n",
    "    cumulative_returns = cumulative_returns.sort_values(ascending=False)\n",
    "    \n",
    "    # PASO 3: Seleccionar top 10 para el portafolio\n",
    "    num_stocks = min(10, len(cumulative_returns))\n",
    "    portfolio_symbols = cumulative_returns.head(num_stocks).index.tolist()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Portafolio seleccionado (Top {num_stocks}):\")\n",
    "    for i, symbol in enumerate(portfolio_symbols, 1):\n",
    "        print(f\"  {i:2d}. {symbol:6s} - {cumulative_returns[symbol]:+7.2f}%\")\n",
    "    \n",
    "    # PASO 4: Analizar performance en per√≠odo de an√°lisis\n",
    "    portfolio_data = last_6_months[portfolio_symbols].dropna(axis=1)\n",
    "    if portfolio_data.empty:\n",
    "        print(\"‚ùå No hay datos suficientes para an√°lisis de performance\")\n",
    "        return None\n",
    "    \n",
    "    # Calcular rendimientos mensuales individuales y del portafolio\n",
    "    individual_monthly_returns = portfolio_data.pct_change().fillna(0) * 100\n",
    "    portfolio_monthly_returns = individual_monthly_returns.mean(axis=1)  # Equal-weighted\n",
    "    \n",
    "    # PASO 5: Calcular estad√≠sticas del portafolio\n",
    "    total_return = ((1 + portfolio_monthly_returns/100).cumprod().iloc[-1] - 1) * 100\n",
    "    volatility = portfolio_monthly_returns.std() * np.sqrt(12)  # Anualizada\n",
    "    avg_monthly_return = portfolio_monthly_returns.mean()\n",
    "    \n",
    "    print(f\"\\nüìä ESTAD√çSTICAS DEL PORTAFOLIO:\")\n",
    "    print(f\"  ‚Ä¢ Rendimiento total:       {total_return:+7.2f}%\")\n",
    "    print(f\"  ‚Ä¢ Rendimiento mensual:     {avg_monthly_return:+7.2f}%\")\n",
    "    print(f\"  ‚Ä¢ Volatilidad anualizada:  {volatility:7.2f}%\")\n",
    "    \n",
    "    # PASO 6: Mostrar rendimientos individuales per√≠odo an√°lisis\n",
    "    individual_cumulative = ((portfolio_data.iloc[-1] / portfolio_data.iloc[0]) - 1) * 100\n",
    "    print(f\"\\nüìà RENDIMIENTOS INDIVIDUALES (Per√≠odo an√°lisis):\")\n",
    "    for symbol in individual_cumulative.sort_values(ascending=False).index:\n",
    "        print(f\"  {symbol:6s}: {individual_cumulative[symbol]:+7.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'portfolio_symbols': portfolio_data.columns.tolist(),\n",
    "        'individual_monthly_returns': individual_monthly_returns,\n",
    "        'portfolio_monthly_returns': portfolio_monthly_returns,\n",
    "        'portfolio_cumulative_return': total_return,\n",
    "        'portfolio_volatility': volatility\n",
    "    }\n",
    "\n",
    "# EJECUCI√ìN PARTE 3\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== PARTE 3: AN√ÅLISIS DE PORTAFOLIO ===\")\n",
    "    \n",
    "    # Analizar portafolio de momentum\n",
    "    results = analyze_momentum_portfolio()\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n‚úÖ PARTE 3 COMPLETADA\")\n",
    "        print(\"\\nüéØ ESTRATEGIA IMPLEMENTADA:\")\n",
    "        print(\"  - Selecci√≥n: Top 10 con mayor momentum (primeros 6 meses)\")\n",
    "        print(\"  - Portafolio: Equal-weighted (10% por acci√≥n)\")\n",
    "        print(\"  - An√°lisis: Performance √∫ltimos 6 meses\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå PARTE 3 FALL√ì - Revisa los datos de entrada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
